# Mediapipeline

  This is an application that I built to process a large library of high-res audio files.  The application will create RAR archives
  of the local files, upload the archives to S3, and then transcode the files to 320Kbps MP3 using  ElasticTranscoder.  The archives
  will be aged-out to Glacier for inexpensive, long-term durable storage.
  
  The application is implemented as a CLI that runs on both on the local machine responsible for archiving and uploading the files, and an EC2 instance that
  deals with some of the processing that occurs in AWS, such as tagging the ElasticTranscoder output with the proper ID3 tag data.  Running a command from the CLI
  using the -h switch will print detailed usage information.
  
  The AWS resources are all created using CloudFormation, and there is a CLI command for creating the entire stack in the AWS region of choice.  The application makes
  extensive use of AWS services, including CloudFormation, S3, SQS, SNS, ElasticTranscoder, EC2, Kinesis, and DynamoDB.  With the recent service launches of AWS Lambda and
  S3 events, it will be possible to alter this architecture such that much of the SQS queuing can be eliminated.  When these new services become generally available,
  I will be making that change.
  
  While I built this application to serve a practical purpose, this is also a good example of how to do batch processing in the cloud.  Feel free to clone into this repo and play around with
  it!

## Installation

Clone the repo from github:

    $ git clone https://github.com/npslater/MediaPipeline
    
Build and install the gem locally.  I recommend using RVM:

    $ rvm gemset create mediapipeline
    $ rvm gemset use mediapipeline
    $ bundle install
    $ rake install

## Usage

Detailed usage for all the commands available in the CLI can be found by running:

    $ mediapipeline
    
First, configure the application:

    $ mediapipeline configure
    
The usage will explain what each configuration setting means.  You can also look at the comments in the master config file:

    $ cat conf/config.yml
    
You will need to install a RAR binary in order to complete the configuration.
    
Next, set up the necessary environment variables:

    $ export AWS_ACCESS_KEY_ID=[Your AWS API ACCESS Key]
    $ export AWS_SECRET_ACCESS_KEY=[Your AWS API Secret Key]
    $ export ENVIRONMENT = [Development|Test|Production]
    
Now build the stack (I've tested this in US-EAST-1 and US-WEST-2 regions):

    $ mediapipeline create
    
Once the stack has been created, you can run the tests.  You will need to set the properties in test config file.  These are the same as the application config, but
there are some additional properties required to run the tests.  You'll also need some sample input audio files.  Any lossless format should work, but I've tested
primarily with MPEG4/Apple Lossless:

    $ vi spec/config.yml
    $ rspec spec/
    
If the tests pass, you should be good to go.  You can now start processing local lossless audio files:

    $ mediapipeline process-files
    
Log output is written to STDOUT by default, but you can also redirect this to a file using the appropriate command line option.  Since logging is being generated by both the
local process as well as that running in EC2, it's useful to aggregate all the log data.  One way to do this is to pipe the log output into Kinesis.  The EC2 instance is
already set up to do this, but if you want to do it locally, do:

    $ mediapipeline process-files [...] | logreader [...]
    
The logreader usage will explain how to use it.  Currently, the application doesn't ship with a client for reading the log data out of the Kinesis stream, but
this is easy to implement using the KCL or one of the existing KCL connectors to other AWS services, like S3.

Finally, there is a command for analyzing a local libary of media files:

    $ mediapipeline analyze
    
This creates some reports showing information about the size of the library, the attributes that will be stored in DynamoDB, as well as the total number
of minutes that will be transcoded.  This is all very useful for estimating how much it will cost to run this pipeline on a sizable library.  In my case,
this was vital as I have upwards of 2TB of audio files.

## Contributing

1. Fork it ( https://github.com/[my-github-username]/mediapipeline/fork )
2. Create your feature branch (`git checkout -b my-new-feature`)
3. Commit your changes (`git commit -am 'Add some feature'`)
4. Push to the branch (`git push origin my-new-feature`)
5. Create a new Pull Request
